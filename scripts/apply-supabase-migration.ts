import { getSupabaseAdminClient } from '../lib/supabase';
import fs from 'fs';
import path from 'path';

interface MigrationResult {
  file: string;
  success: boolean;
  error?: any;
  duration: number;
}

async function executeMigration(sql: string): Promise<void> {
  const supabase = getSupabaseAdminClient();
  await supabase.rpc('exec_sql', { sql });
}

async function backupTable(tableName: string): Promise<void> {
  const supabase = getSupabaseAdminClient();
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const backupTable = `${tableName}_backup_${timestamp}`;
  
  await supabase.rpc('exec_sql', {
    sql: `CREATE TABLE IF NOT EXISTS ${backupTable} AS SELECT * FROM ${tableName};`
  });
}

async function main() {
  const results: MigrationResult[] = [];
  const migrationPath = path.join(process.cwd(), 'supabase', 'migrations', '20240527000000_add_performance_indexes.sql');

  try {
    console.log('ðŸ”„ Starting migration process...\n');

    // 1. Lecture du fichier de migration
    console.log('ðŸ“– Reading migration file...');
    const migrationSQL = fs.readFileSync(migrationPath, 'utf8');

    // 2. Backup des tables concernÃ©es
    console.log('\nðŸ“¦ Creating backups...');
    const tablesToBackup = ['users', 'orders', 'payments', 'subscriptions', 'deliveries', 'prospects', 'network_stats'];
    
    for (const table of tablesToBackup) {
      console.log(`   Backing up ${table}...`);
      await backupTable(table);
    }

    // 3. ExÃ©cution de la migration
    console.log('\nâš¡ Executing migration...');
    const start = Date.now();
    
    try {
      await executeMigration(migrationSQL);
      
      results.push({
        file: '20240527000000_add_performance_indexes.sql',
        success: true,
        duration: Date.now() - start
      });
    } catch (error) {
      results.push({
        file: '20240527000000_add_performance_indexes.sql',
        success: false,
        error,
        duration: Date.now() - start
      });
    }

    // 4. VÃ©rification des index
    console.log('\nðŸ” Verifying indexes...');
    const supabase = getSupabaseAdminClient();
    
    // VÃ©rifier que les index ont Ã©tÃ© crÃ©Ã©s
    const { data: indexes, error: indexError } = await supabase.rpc('exec_sql', {
      sql: `
        SELECT schemaname, tablename, indexname 
        FROM pg_indexes 
        WHERE schemaname = 'public'
        AND indexname LIKE 'idx_%';
      `
    });

    if (indexError) {
      throw new Error(`Failed to verify indexes: ${indexError.message}`);
    }

    // 5. Afficher les rÃ©sultats
    console.log('\nðŸ“Š Migration Results:');
    console.log('===================\n');

    results.forEach(result => {
      const status = result.success ? 'âœ…' : 'âŒ';
      console.log(`${status} ${result.file} (${result.duration}ms)`);
      
      if (!result.success) {
        console.log(`   Error: ${result.error?.message || result.error}`);
      }
    });

    // 6. VÃ©rifier les index crÃ©Ã©s
    console.log('\nðŸ“‘ Created Indexes:');
    console.log('=================\n');
    
    if (indexes && Array.isArray(indexes)) {
      indexes.forEach((idx: any) => {
        console.log(`âœ“ ${idx.indexname} on ${idx.tablename}`);
      });
    }

    // 7. RÃ©sumÃ© final
    const successful = results.filter(r => r.success).length;
    const failed = results.filter(r => !r.success).length;

    console.log('\nðŸ“ˆ Summary:');
    console.log(`âœ… ${successful} migrations successful`);
    console.log(`âŒ ${failed} migrations failed`);
    console.log(`ðŸ“¦ ${tablesToBackup.length} tables backed up`);
    console.log(`ðŸ“‘ ${indexes?.length || 0} indexes verified`);

    if (failed > 0) {
      process.exit(1);
    }

  } catch (error) {
    console.error('\nâŒ Migration failed:', error);
    process.exit(1);
  }
}

// ExÃ©cuter la migration
console.log('ðŸš€ Starting Supabase migration process...\n');
main().catch(error => {
  console.error('Fatal error:', error);
  process.exit(1);
}); 